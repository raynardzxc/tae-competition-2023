---
title: "R Notebook"
output: html_notebook
---

# Trying Stuff
## Import Libraries
```{r}
rm(list=ls())
# Execute our custom script for loading packages
source("usePackages.R")
# Name of the packages 
pkgnames <- c("mlogit","dplyr","splitTools")
# Use our custom load function
loadPkgs(pkgnames)
```

## Import Data
```{r}
safety <- read.csv("../input/train1_preprocessed.csv")
safety$segment <- as.factor(safety$segment)
safety$ppark <- as.factor(safety$ppark)
safety$gender <- as.factor(safety$gender)
safety$educ <- as.factor(safety$educ)
safety$region <- as.factor(safety$region)
safety$Urb <- as.factor(safety$Urb)
str(safety)
head(safety)
```
## Getting column id's of start and end
```{r}
which(colnames(safety)=="CC1")
which(colnames(safety)=="Price4")
```

## Split train-test
```{r}
# Split data into partitions
set.seed(42)
inds <- partition(safety$Choice, p = c(train = 0.8, test = 0.2))
str(inds)
```

```{r}
train_set <- safety[inds$train, ]
test_set <- safety[inds$test, ]
table(train_set$Choice)
table(test_set$Choice)
```

```{r}
S<-dfidx(train_set, shape="wide", choice="Choice", varying =c(4:83), sep="",idx = list(c("No", "Case")))
# segment+year+milesa+nighta+ppark+gender+agea+educ+region+Urb+incomea
# | segment+ppark+gender+educ+region+Urb
# | year+milesa+nighta+agea+incomea
```

```{r}
M1 <- mlogit(Choice~CC+GN+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price | year+ppark+Urb+region+educ+gender+milesa+nighta+agea+incomea+0, data=S, rpar=c(CC='n', FA='n',LD='n',BZ='n',FC='n',FP='n',RP='n',PP='n',KA='n',SC='n',TS='n',NV='n',MA='n',LB='n',AF='n',HU='n',Price='n'), panel = TRUE, print.level=TRUE)
# segment doesnt work
```

```{r}
summary(M1)
```

```{r}
M1loglik<-round(as.numeric(M1$logLik),digits=2)
M1loglik
```


```{r}
Test <- dfidx(test_set, shape="wide", choice="Choice", varying = c(4:83), sep="",idx = list(c("No", "Case")))
TestPredict1 <- predict(M1, newdata=Test)
PredictedChoice1 <- apply(TestPredict1,1,which.max)
ActualChoice1 <- test_set[,"Choice"]
Tabtestmixed= table(PredictedChoice1, ActualChoice1)
Tabtestmixed

logloss <- function(test_set, testpredict_df) {
  # Create one-hot encoding for each choice on-the-fly
  Ch1 <- as.integer(test_set$Choice == 1)
  Ch2 <- as.integer(test_set$Choice == 2)
  Ch3 <- as.integer(test_set$Choice == 3)
  Ch4 <- as.integer(test_set$Choice == 4)
  
  # Calculate logloss using these one-hot encoded variables
  result <- -1/nrow(test_set) * sum(Ch1 * log(testpredict_df$Ch1) +
                                    Ch2 * log(testpredict_df$Ch2) +
                                    Ch3 * log(testpredict_df$Ch3) +
                                    Ch4 * log(testpredict_df$Ch4))
  return(result)
}

# Calculate logloss
logloss_value <- logloss(test_set, testpredict_df)
print(paste0("Test LogLoss: ", logloss_value))

```

# Generate Predictions
```{r}
predict_data <- read.csv("../input/test1_preprocessed.csv")
predict_data$segment <- as.factor(predict_data$segment)
predict_data$ppark <- as.factor(predict_data$ppark)
predict_data$gender <- as.factor(predict_data$gender)
predict_data$educ <- as.factor(predict_data$educ)
predict_data$region <- as.factor(predict_data$region)
predict_data$Urb <- as.factor(predict_data$Urb)

which(colnames(predict_data)=="CC1")
which(colnames(predict_data)=="Price4")

# Compare names and class of each column
# identical(names(predict_data), names(test_set)) & identical(sapply(predict_data, class), sapply(test_set, class))
```

```{r}
# The factor variables
factor_vars <- c("segment", "ppark", "gender", "educ", "region", "Urb")

# Convert the variables to factor in predict_data
predict_data[factor_vars] <- lapply(predict_data[factor_vars], as.factor)

# Convert the variables to factor in test_set
test_set[factor_vars] <- lapply(test_set[factor_vars], as.factor)

# Check if there are new levels in predict_data
for (var in factor_vars) {
  print(paste("Checking variable:", var))
  
  test_levels <- levels(test_set[[var]])
  predict_levels <- levels(predict_data[[var]])
  
  new_levels <- setdiff(predict_levels, test_levels)
  
  if (length(new_levels) > 0) {
    print(paste("Variable", var, "has new levels in predict_data:", paste(new_levels, collapse = ", ")))
  } else {
    print(paste("No new levels in variable", var))
  }
}
```

```{r}
levels(test_set$segment)
levels(predict_data$segment)
```


```{r}
predict_set <- dfidx(predict_data, shape="wide", choice="Choice", varying = c(4:83), sep="",idx = list(c("No", "Case")))
prediction <- predict(M1, newdata=predict_set)
```

```{r}
# Converting the prediction matrix into a data frame
prediction_df <- as.data.frame(prediction)
# Renaming the columns as per your requirement
colnames(prediction_df) <- c("Ch1", "Ch2", "Ch3", "Ch4")
# Adding the 'No' column from original dataset to the prediction data frame
prediction_df$No <- predict_data$No
# Rearranging the columns
prediction_df <- prediction_df[c("No", "Ch1", "Ch2", "Ch3", "Ch4")]

# Writing the output to a csv file
write.csv(prediction_df, file = "../output/submission.csv", row.names = FALSE)
```

# LBG
```{r}
rm(list=ls())
# Execute our custom script for loading packages
source("usePackages.R")
# Name of the packages 
pkgnames <- c("lightgbm","data.table","caret","splitTools")
# Use our custom load function
loadPkgs(pkgnames)
```

```{r}
# Load the dataset
safety <- read.csv("../input/train1_preprocessed.csv")

# Exclude first three columns
safety <- safety[, -c(1:3)]

# Convert 'Choice' to factor
safety$Choice <- as.factor(safety$Choice)
```

```{r}
# Set seed for reproducibility
set.seed(42)

# Partition data
inds <- partition(safety$Choice, p = c(train = 0.8, test = 0.2))

# Create training and testing sets
train_set <- safety[inds$train, ]
test_set <- safety[inds$test, ]

# Convert categorical features to integer
categorical_features <- c('segment', 'ppark', 'gender', 'educ', 'region', 'Urb')
train_set[categorical_features] <- lapply(train_set[categorical_features], function(x) as.integer(as.factor(x)))
test_set[categorical_features] <- lapply(test_set[categorical_features], function(x) as.integer(as.factor(x)))

# Create lgb.Dataset objects
train_data <- lgb.Dataset(data = as.matrix(train_set[, -which(names(train_set) == "Choice")]),
                          label = train_set$Choice)

test_data <- lgb.Dataset(data = as.matrix(test_set[, -which(names(test_set) == "Choice")]),
                         label = test_set$Choice)
```

```{r}
# Set parameters
params <- list(objective = "multiclass",
               metric = "multi_logloss",
               num_class = length(unique(safety$Choice)),
               num_iterations = 100,
               learning_rate = 0.1,
               verbosity = -1)


# Train the model
model <- lgb.train(params,
                   data = train_data,
                   valids = list(test = test_data),
                   nrounds = 100,
                   early_stopping_rounds = 10)
```

```{r}
# Predict on the test set
preds <- predict(model, as.matrix(test_set[, -which(names(test_set) == "Choice")]))

# Reshape the predictions to a matrix with one column per class
preds <- matrix(preds, ncol = length(unique(safety$Choice)), byrow = TRUE)

# Calculate log loss
logloss <- -mean(sum(test_set$Choice * log(preds)))
print(paste0("Test LogLoss: ", logloss))
```

