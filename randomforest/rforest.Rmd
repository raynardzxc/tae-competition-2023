---
title: "Random Forest"
output: html_notebook
---

## Import libraries
```{r}
rm(list=ls())
library(randomForest)
library(mltools)
library(data.table)
library(dfidx)
```

## Loading data
```{r}
totrain<- read.csv("train1_rforest_preprocessed.csv")
topredict <- read.csv("test1_rforest_preprocessed.csv")
```


## Processing data to train model
```{r}

## Split to train and test by Case -> so we are training and testing on the same person
train <- dfidx(subset(totrain, Task<=12), shape="wide", choice="Choice", sep="", varying = c(4:83), idx = c("No", "Case"))
test <- dfidx(subset(totrain, Task>12), shape="wide", choice="Choice", sep="", varying = c(4:83), idx = c("No", "Case"))

## Convert back to dataframe
train <- as.data.frame(train)
test <- as.data.frame(test)

## drop Task
train <- subset(train, select = -c(Task,idx))
test <- subset(test, select = -c(Task,idx))

# train$Choice <- as.integer(train$Choice)
# test$Choice <- as.integer(test$Choice)
# 
# ## split to x and y because idk why the formula one doesnt work
# train_x <- subset(train, select = -c(Choice))
# train_y <- subset(train, select = c(Choice))
# test_x <- subset(test, select = -c(Choice))
# test_y <- subset(test, select = c(Choice))
# 
# train_y$Choice <- as.factor(train_y$Choice)
# test_y$Choice <- as.factor(test_y$Choice)

```

## Preparing topredict for later
```{r}
predict_set <- dfidx(subset(topredict, Task<=19), shape="wide", choice="Choice", sep="", varying = c(4:83), idx = c("No", "Case"))

predict_set <- as.data.frame(predict_set)
predict_set <- subset(predict_set, select = -c(Task,idx))
```



## Idk how to fix error when trying to do as.factor(Choice)~. so this is my work around
```{r}
# names <- colnames(train)
# # names
# # length(names)
# temp = ""
# for (i in 1:length(names)){
#   if (names[i]!="Choice"){
#     temp <- paste(temp, names[i], sep = "`+train$`")
#   }
# }
# temp
```



## Creating model
```{r}
## planting my trees
set.seed(100)
m1<- randomForest(as.factor(Choice)~.,data = train)
#m1 <- randomForest(as.factor(train$Choice)~train$`segment_Full-size Pickup`+train$`segment_Midsize Car`)
#m1 <- randomForest(as.factor(train$Choice)~train$`segment_Full-size Pickup`+train$`segment_Midsize Car`+train$`segment_Midsize Luxury Utility segements`+train$`segment_Midsize Utility`+train$`segment_Prestige Luxury Sedan`+train$`segment_Small Car`+train$`yearind`+train$`milesa`+train$`nighta`+train$`ppark_Daily`+train$`ppark_Monthly`+train$`ppark_Never`+train$`ppark_Weekly`+train$`ppark_Yearly`+train$`gender_Female`+train$`gender_Male`+train$`agea`+train$`educ_College Graduate (4 Years)`+train$`educ_Grade School`+train$`educ_High School`+train$`educ_Postgraduate College`+train$`educ_Some College (1-3 Years)`+train$`educ_Trade/Vocational School`+train$`region_MW`+train$`region_NE`+train$`region_SE`+train$`region_SW`+train$`region_W`+train$`Urbind`+train$`incomea`+train$`CC`+train$`GN`+train$`NS`+train$`BU`+train$`FA`+train$`LD`+train$`BZ`+train$`FC`+train$`FP`+train$`RP`+train$`PP`+train$`KA`+train$`SC`+train$`TS`+train$`NV`+train$`MA`+train$`LB`+train$`AF`+train$`HU`+train$`Price`)

#m2 <- randomForest(as.factor(Choice)~milesa+agea+incomea+Price+nighta+yearind, data = train)
# m1 <- randomForest(train_x,train_y,test_x,test_y)
#summary(m1)
#importance(m1)
```

## Testing model
```{r}
predictforest1 <- predict(m1,newdata=test)
acc <- table(test$Choice,predictforest1)
acc <- sum(diag(acc))/sum(acc)
acc #0.7791378
```

## Checking area for improvement
```{r}
summary(m1)
importance(m1)
varImpPlot(m1)
```
## Better model (MeanDecreaseGini >800)
```{r}
set.seed(100)
m2<- randomForest(as.factor(Choice)~ milesa+nighta+agea+incomea+Price,data = train, ntree = 500)
```

## Testing better model
```{r}
predictforest2 <- predict(m2,newdata=test)
acc2 <- table(test$Choice,predictforest2)
acc2 <- sum(diag(acc2))/sum(acc2)
acc2 #0.7801447
```
## Getting final prediction
```{r}
prediction <- predict(m2,newdata=predict_set)
prediction_df <- as.data.frame(prediction)
#colnames(prediction_df) <- c("Ch1", "Ch2", "Ch3", "Ch4")
```

